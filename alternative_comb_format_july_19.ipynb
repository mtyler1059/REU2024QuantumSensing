{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5h0kjKL0wqX"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define comb creation functions\n",
        "def comb_x(cps1):\n",
        "  comb_x_values = np.fft.fftfreq(n = int(cps1['time'] * cps1['sample_rate']), d = 1 / cps1['sample_rate'])\n",
        "  return comb_x_values\n",
        "\n",
        "def calculate_h(cps2, comb_x_values_i):\n",
        "  path_length = 100e-3\n",
        "  speed_of_light = 3e8\n",
        "  refractive_index = cps2['n_0']\n",
        "  absorption_coefficient = cps2['alpha_0']\n",
        "  refractive_index_transformed = refractive_index + 0.1 * np.sin(comb_x_values_i*2*np.pi)\n",
        "  absorption_coeffient_transoformed = absorption_coefficient * np.exp(-comb_x_values_i / 1.5e14)\n",
        "  H_absorption_value = np.exp(-absorption_coeffient_transoformed * path_length)\n",
        "  H_phase_value = np.exp(-1j * 2 * np.pi * comb_x_values_i * (refractive_index_transformed - 1) * path_length / speed_of_light)\n",
        "  H_value = H_absorption_value * H_phase_value\n",
        "  return H_value\n",
        "\n",
        "def comb_y(cps3, comb_x_values_j):\n",
        "  # Identify the basic independent variable points representing the entire wave, known as samples\n",
        "  number_of_samples = int(cps3['time'] * cps3['sample_rate'])\n",
        "  sample_set = np.zeros(number_of_samples) # Unit is 'number of samples,' representing total amount of points present in the grand train\n",
        "\n",
        "  # Addresses pulses in the wave\n",
        "  number_of_pulses_without_reference_to_samples = int(cps3['time'] * cps3['rep_rate'])\n",
        "  amount_of_samples_coincident_with_pulses = int(cps3['pulse_duration'] * cps3['sample_rate']) # in just one pulse\n",
        "\n",
        "  # Identify the time points (with units of seconds, not to be confused with sample points) at which pulses start\n",
        "  pulse_drift_black_box = np.linspace(0,\n",
        "                                      cps3['drift'] / cps3['rep_rate'],\n",
        "                                      number_of_pulses_without_reference_to_samples) * np.exp(np.linspace(0,\n",
        "                                                                                                          100 * cps3['drift'],\n",
        "                                                                                                          number_of_pulses_without_reference_to_samples))\n",
        "  pulse_times_noise_black_box = np.random.normal(loc = np.arange(number_of_pulses_without_reference_to_samples) / cps3['rep_rate'],\n",
        "                                                 scale = cps3['jitter'] / cps3['rep_rate'],\n",
        "                                                 size = number_of_pulses_without_reference_to_samples)\n",
        "\n",
        "  # Synthesize to determine pulse time start points\n",
        "  actual_pulse_time_start_points = np.add(pulse_times_noise_black_box,\n",
        "                                          pulse_drift_black_box)\n",
        "\n",
        "  # Wherever sample points are coincident with pulse points, set those sample values to one\n",
        "  for actual_pulse_time_start_point in actual_pulse_time_start_points:\n",
        "    starting_sample = int(actual_pulse_time_start_point * cps3['sample_rate'])\n",
        "    if starting_sample + amount_of_samples_coincident_with_pulses < number_of_samples:\n",
        "      sample_set[starting_sample:starting_sample + amount_of_samples_coincident_with_pulses] = 1\n",
        "\n",
        "  # Add noise to all points of the sample train\n",
        "  sample_set += cps3['noise'] * np.random.normal(size = number_of_samples)\n",
        "\n",
        "  # Perform Fourier transform on the sample train to identify ampltidues of constituent frequencies\n",
        "  fourier_amplitudes = np.fft.fft(sample_set)\n",
        "\n",
        "  # Modify spectrum according to H parameter\n",
        "  h_parameter = calculate_h(cps3, comb_x_values_j)\n",
        "  final_amplitudes = fourier_amplitudes * h_parameter\n",
        "  return np.abs(final_amplitudes)\n",
        "\n",
        "def find_center(start_freq, first_harmon_width0):\n",
        "  center = start_freq + (0.5 * first_harmon_width0)\n",
        "  return center\n",
        "\n",
        "def trim_data(final_x_axis0, final_y_axis0, horizontal_comb_shift0, width_of_each_comb0):\n",
        "  lower_bound_first_harmonic = horizontal_comb_shift0 - (0.5 * width_of_each_comb0)\n",
        "  upper_bound_first_harmonic = horizontal_comb_shift0 + (0.5 * width_of_each_comb0)\n",
        "\n",
        "  new_x_axis = []\n",
        "  new_y_axis = []\n",
        "\n",
        "  for individual in range(len(final_x_axis0)):\n",
        "    if final_x_axis0[individual] >= lower_bound_first_harmonic and final_x_axis0[individual] < upper_bound_first_harmonic:\n",
        "      new_x_axis.append(final_x_axis0[individual])\n",
        "      new_y_axis.append(final_y_axis0[individual])\n",
        "\n",
        "  grand_update = []\n",
        "  grand_update.append(new_x_axis)\n",
        "  grand_update.append(new_y_axis)\n",
        "  return grand_update"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add all input\n",
        "ir_spectrum_unprocessed = np.load('/content/10NoisyIRSpectra_7_19.npy')\n",
        "input_ir_x_axis = ir_spectrum_unprocessed[0]\n",
        "teeth_spacing = 1\n",
        "width_of_each_comb = 20\n",
        "start_frequency_arrays = [1290, 1690, 2290, 2690]\n",
        "\n",
        "# Specify path to output, including output file name\n",
        "output_path = '/content/output.npy'"
      ],
      "metadata": {
        "id": "erbdAf0R06tC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = input_ir_x_axis\n",
        "grand_x = np.linspace(0, 4000, 4000000, endpoint = False)\n",
        "output = []\n",
        "output.append(grand_x)\n",
        "\n",
        "for stance in range(1, ir_spectrum_unprocessed.shape[0]):\n",
        "  input_ir_y_axis = ir_spectrum_unprocessed[stance]\n",
        "  transmittance_values = input_ir_y_axis / (np.max(input_ir_y_axis)) # Normalize\n",
        "  grand_y = np.zeros(len(grand_x))\n",
        "\n",
        "  for guide in range(len(start_frequency_arrays)):\n",
        "    ### START COMB CREATION\n",
        "    # Main parameters\n",
        "    peak_spacing = teeth_spacing\n",
        "    wavenumber_broadness = 3 * width_of_each_comb\n",
        "    horizontal_comb_shift = find_center(start_frequency_arrays[guide], width_of_each_comb)\n",
        "    noise_of_pulse = 0.00\n",
        "\n",
        "    # Other parameters\n",
        "    drift_comb = 0.000                  # Jack set this parameter to 0.010\n",
        "    jitter_comb = 0.000\n",
        "    refractive_index_comb = 000.0\n",
        "    absorption_coefficient_comb = 0.0\n",
        "    total_experiment_duration = 1e3\n",
        "\n",
        "    # Apply parameters\n",
        "    broadness_of_comb = wavenumber_broadness / 100\n",
        "    comb_parameters = {'rep_rate': peak_spacing,\n",
        "                      'pulse_duration': 60e-3 * (1 / broadness_of_comb),\n",
        "                      'time': total_experiment_duration,\n",
        "                      'sample_rate': 100e0 * broadness_of_comb,\n",
        "                      'noise': noise_of_pulse,\n",
        "                      'jitter': jitter_comb,\n",
        "                      'drift': drift_comb,\n",
        "                      'n_0': refractive_index_comb,\n",
        "                      'alpha_0': absorption_coefficient_comb}\n",
        "\n",
        "    # Pass input through comb creation functions defined above\n",
        "    comb_x_axis = comb_x(comb_parameters)\n",
        "    comb_y_axis = comb_y(comb_parameters, comb_x_axis)\n",
        "    final_x_axis = comb_x_axis + horizontal_comb_shift\n",
        "    final_y_axis = comb_y_axis / (np.max(comb_y_axis))\n",
        "\n",
        "    new_values = trim_data(final_x_axis, final_y_axis, find_center(start_frequency_arrays[guide], width_of_each_comb), width_of_each_comb)\n",
        "\n",
        "    # Interpolate IR spectra values and simulate interaction with comb\n",
        "    ir_spectrum_interpolated_values = np.interp(x = new_values[0], xp = frequencies, fp = transmittance_values)\n",
        "    exiting_comb = ir_spectrum_interpolated_values * new_values[1]\n",
        "\n",
        "    sorted_indices = np.argsort(new_values[0])\n",
        "\n",
        "    updated_x = []\n",
        "    updated_y = []\n",
        "    for finality in sorted_indices:\n",
        "      updated_x.append(new_values[0][finality])\n",
        "      updated_y.append(exiting_comb[finality])\n",
        "    ### END COMB CREATION\n",
        "\n",
        "    for _,candidate in enumerate(grand_x):\n",
        "      if candidate == updated_x[0]:\n",
        "        start_place = _\n",
        "        break\n",
        "\n",
        "    for ticker in range(len(updated_x)):\n",
        "      grand_y[start_place + ticker] = updated_y[ticker]\n",
        "\n",
        "  output.append(grand_y)\n",
        "np.save(output_path, output)"
      ],
      "metadata": {
        "id": "uElI8lJfCoIU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}