{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import standard libraries and define comb creation functions"
      ],
      "metadata": {
        "id": "njQXWNSzPQz8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7PmyMtKmSE7"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Define comb creation functions\n",
        "def comb_x(cps1):\n",
        "  comb_x_values = np.fft.fftfreq(n = int(cps1['time'] * cps1['sample_rate']), d = 1 / cps1['sample_rate'])\n",
        "  return comb_x_values\n",
        "\n",
        "def calculate_h(cps2, comb_x_values_i):\n",
        "  path_length = 100e-3\n",
        "  speed_of_light = 3e8\n",
        "  refractive_index = cps2['n_0']\n",
        "  absorption_coefficient = cps2['alpha_0']\n",
        "  refractive_index_transformed = refractive_index + 0.1 * np.sin(comb_x_values_i*2*np.pi)\n",
        "  absorption_coeffient_transoformed = absorption_coefficient * np.exp(-comb_x_values_i / 1.5e14)\n",
        "  H_absorption_value = np.exp(-absorption_coeffient_transoformed * path_length)\n",
        "  H_phase_value = np.exp(-1j * 2 * np.pi * comb_x_values_i * (refractive_index_transformed - 1) * path_length / speed_of_light)\n",
        "  H_value = H_absorption_value * H_phase_value\n",
        "  return H_value\n",
        "\n",
        "def comb_y(cps3, comb_x_values_j):\n",
        "  # Identify the basic independent variable points representing the entire wave, known as samples\n",
        "  number_of_samples = int(cps3['time'] * cps3['sample_rate'])\n",
        "  sample_set = np.zeros(number_of_samples) # Unit is 'number of samples,' representing total amount of points present in the grand train\n",
        "\n",
        "  # Addresses pulses in the wave\n",
        "  number_of_pulses_without_reference_to_samples = int(cps3['time'] * cps3['rep_rate'])\n",
        "  amount_of_samples_coincident_with_pulses = int(cps3['pulse_duration'] * cps3['sample_rate']) # in just one pulse\n",
        "\n",
        "  # Identify the time points (with units of seconds, not to be confused with sample points) at which pulses start\n",
        "  pulse_drift_black_box = np.linspace(0,\n",
        "                                      cps3['drift'] / cps3['rep_rate'],\n",
        "                                      number_of_pulses_without_reference_to_samples) * np.exp(np.linspace(0,\n",
        "                                                                                                          100 * cps3['drift'],\n",
        "                                                                                                          number_of_pulses_without_reference_to_samples))\n",
        "  pulse_times_noise_black_box = np.random.normal(loc = np.arange(number_of_pulses_without_reference_to_samples) / cps3['rep_rate'],\n",
        "                                                 scale = cps3['jitter'] / cps3['rep_rate'],\n",
        "                                                 size = number_of_pulses_without_reference_to_samples)\n",
        "\n",
        "  # Synthesize to determine pulse time start points\n",
        "  actual_pulse_time_start_points = np.add(pulse_times_noise_black_box,\n",
        "                                          pulse_drift_black_box)\n",
        "\n",
        "  # Wherever sample points are coincident with pulse points, set those sample values to one\n",
        "  for actual_pulse_time_start_point in actual_pulse_time_start_points:\n",
        "    starting_sample = int(actual_pulse_time_start_point * cps3['sample_rate'])\n",
        "    if starting_sample + amount_of_samples_coincident_with_pulses < number_of_samples:\n",
        "      sample_set[starting_sample:starting_sample + amount_of_samples_coincident_with_pulses] = 1\n",
        "\n",
        "  # Add noise to all points of the sample train\n",
        "  sample_set += cps3['noise'] * np.random.normal(size = number_of_samples)\n",
        "\n",
        "  # Perform Fourier transform on the sample train to identify ampltidues of constituent frequencies\n",
        "  fourier_amplitudes = np.fft.fft(sample_set)\n",
        "\n",
        "  # Modify spectrum according to H parameter\n",
        "  h_parameter = calculate_h(cps3, comb_x_values_j)\n",
        "  final_amplitudes = fourier_amplitudes * h_parameter\n",
        "  return np.abs(final_amplitudes)\n",
        "\n",
        "def find_center(start_freq, first_harmon_width):\n",
        "  center = start_freq + (0.5 * first_harmon_width)\n",
        "  return center\n",
        "\n",
        "def trim_data(final_x_axis0, final_y_axis0, horizontal_comb_shift0, width_of_each_comb0):\n",
        "  lower_bound_first_harmonic = horizontal_comb_shift0 - (0.5 * width_of_each_comb0)\n",
        "  upper_bound_first_harmonic = horizontal_comb_shift0 + (0.5 * width_of_each_comb0)\n",
        "\n",
        "  new_x_axis = []\n",
        "  new_y_axis = []\n",
        "\n",
        "  for individual in range(len(final_x_axis0)):\n",
        "    if final_x_axis0[individual] >= lower_bound_first_harmonic and final_x_axis0[individual] < upper_bound_first_harmonic:\n",
        "      new_x_axis.append(final_x_axis0[individual])\n",
        "      new_y_axis.append(final_y_axis0[individual])\n",
        "\n",
        "  grand_update = []\n",
        "  grand_update.append(new_x_axis)\n",
        "  grand_update.append(new_y_axis)\n",
        "  return grand_update"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add input"
      ],
      "metadata": {
        "id": "HejwvyPNPZEF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add all input\n",
        "ir_spectrum_unprocessed = np.load('/content/10_IR_Spectra_date_7_5.npy')\n",
        "input_ir_x_axis = ir_spectrum_unprocessed[0]\n",
        "input_ir_y_axis = ir_spectrum_unprocessed[1]\n",
        "teeth_spacing = 1\n",
        "width_of_each_comb = 20\n",
        "start_frequency_arrays = [90, 1290, 2290]\n",
        "\n",
        "# Specify path to output, including output file name\n",
        "output_path = '/content/output.csv'"
      ],
      "metadata": {
        "id": "tZ9OHZZsyZ5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate data"
      ],
      "metadata": {
        "id": "up33BBPoPvC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate all data\n",
        "progress = 0\n",
        "for guide in range(len(start_frequency_arrays)):\n",
        "  # Main parameters\n",
        "  peak_spacing = teeth_spacing\n",
        "  wavenumber_broadness = 3 * width_of_each_comb\n",
        "  horizontal_comb_shift = find_center(start_frequency_arrays[guide], 20)\n",
        "  noise_of_pulse = 0.00\n",
        "\n",
        "  # Other parameters\n",
        "  drift_comb = 0.000                  # Jack set this parameter to 0.010\n",
        "  jitter_comb = 0.000\n",
        "  refractive_index_comb = 000.0\n",
        "  absorption_coefficient_comb = 0.0\n",
        "  total_experiment_duration = 1e3\n",
        "\n",
        "\n",
        "  # Apply parameters\n",
        "  broadness_of_comb = wavenumber_broadness / 100\n",
        "  comb_parameters = {'rep_rate': peak_spacing,\n",
        "                    'pulse_duration': 60e-3 * (1 / broadness_of_comb),\n",
        "                    'time': total_experiment_duration,\n",
        "                    'sample_rate': 100e0 * broadness_of_comb,\n",
        "                    'noise': noise_of_pulse,\n",
        "                    'jitter': jitter_comb,\n",
        "                    'drift': drift_comb,\n",
        "                    'n_0': refractive_index_comb,\n",
        "                    'alpha_0': absorption_coefficient_comb}\n",
        "\n",
        "  # Pass input through comb creation functions defined above\n",
        "  comb_x_axis = comb_x(comb_parameters)\n",
        "  comb_y_axis = comb_y(comb_parameters, comb_x_axis)\n",
        "  final_x_axis = comb_x_axis + horizontal_comb_shift\n",
        "  final_y_axis = comb_y_axis / (np.max(comb_y_axis))\n",
        "\n",
        "  new_values = trim_data(final_x_axis, final_y_axis, find_center(start_frequency_arrays[guide], 20), 20)\n",
        "\n",
        "  frequencies = input_ir_x_axis\n",
        "  transmittance_values = input_ir_y_axis / (np.max(input_ir_y_axis)) # Normalize\n",
        "\n",
        "  # Interpolate IR spectra values and simulate interaction with comb\n",
        "  ir_spectrum_interpolated_values = np.interp(x = new_values[0], xp = frequencies, fp = transmittance_values)\n",
        "  exiting_comb = ir_spectrum_interpolated_values * new_values[1]\n",
        "\n",
        "  if guide == 0:\n",
        "    column_names = []\n",
        "    for ex in range(len(new_values[0])):\n",
        "      name = f'comb_point_{ex}'\n",
        "      column_names.append(name)\n",
        "    export = pd.DataFrame(columns = column_names)\n",
        "\n",
        "  sorted_indices = np.argsort(new_values[0])\n",
        "\n",
        "  updated_x = []\n",
        "  updated_y = []\n",
        "  for finality in sorted_indices:\n",
        "    updated_x.append(new_values[0][finality])\n",
        "    updated_y.append(new_values[1][finality])\n",
        "\n",
        "  export.loc[progress] = updated_x\n",
        "  progress = progress + 1\n",
        "  export.loc[progress] = updated_y\n",
        "  progress = progress + 1\n",
        "\n",
        "# Write output to csv\n",
        "export.to_csv(output_path, index = False)"
      ],
      "metadata": {
        "id": "NDCprqc5uWiU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}